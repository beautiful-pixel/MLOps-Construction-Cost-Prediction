# MLOps Platform â€“ Construction Cost Prediction

This project implements an end-to-end MLOps platform built for the Solafune Construction Cost Prediction challenge.

The primary machine learning objective is to predict regional construction costs using a tabular baseline, while preparing the platform for future multimodal modeling with satellite imagery.

Beyond model performance, the core goal is to design a reproducible, modular, production-oriented ML system covering the full lifecycle:

data ingestion â†’ validation â†’ training â†’ promotion â†’ serving â†’ monitoring.

---

# Architecture Overview

The system is structured around clearly separated responsibilities:

âš« **Entry Layer** â†’ Nginx (HTTPS reverse proxy)  
ðŸ”µ **Serving Layer** â†’ Streamlit (app), Gateway API, Inference API  
ðŸŸ¢ **Training Layer** â†’ Airflow, MLflow, PostgreSQL  
ðŸŸ  **Monitoring Layer** â†’ Prometheus, Grafana

```mermaid
%%{init: {'theme':'base'}}%%
flowchart TB

    Nginx["Nginx (HTTPS Entry Point)"]
    Streamlit["Streamlit UI"]
    Gateway["Gateway API"]
    Inference["Inference API"]
    Airflow["Airflow"]
    MLflow["MLflow Registry"]
    Postgres["PostgreSQL"]
    Prometheus["Prometheus"]
    Grafana["Grafana"]

    Nginx -->|/| Streamlit
    Nginx -->|/api| Gateway
    Nginx -->|/grafana| Grafana
    Streamlit --> Gateway
    Inference -->|Load prod model| MLflow
    Gateway -->|List runs| MLflow
    Gateway -->|Trigger training| Airflow
    Gateway -->|Predict| Inference
    Airflow -->|Log & register model| MLflow
    MLflow --> Postgres
    Airflow -->|Reload after promote| Inference
    Prometheus -->|Scrape| Gateway
    Prometheus -->|Scrape| Inference
    Grafana --> Prometheus

    %% Entry Layer
    style Nginx fill:#eeeeee,stroke:#616161,stroke-width:2px

    %% Serving Layer
    style Streamlit fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px
    style Gateway fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px
    style Inference fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px

    %% Training Layer
    style Airflow fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style MLflow fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style Postgres fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px

    %% Monitoring Layer
    style Prometheus fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    style Grafana fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
```

---

# Live Deployment

The platform is deployed on an Oracle Cloud server and orchestrated with Kubernetes.  
It is publicly accessible at https://engineerai.space

The following routes are exposed:

- `/` â†’ Streamlit application  
- `/api` â†’ Gateway API  
- `/grafana` â†’ Monitoring dashboards  

Authentication is required to access protected services.

The Streamlit application acts strictly as a frontend client of the Gateway API.  
It does not communicate directly with Airflow, MLflow, or the Inference service.  
All operational and inference requests pass through the Gateway layer.

---

# API Gateway

The API Gateway is the central orchestration layer of the platform.

All external interactions pass through the gateway.  
No internal service (Airflow, MLflow, Inference API) is exposed directly.

The gateway acts as:

- A control plane for ML operations  
- A secure abstraction layer over Airflow and MLflow  
- A single entry point for both UI and programmatic access  

Full interactive API documentation is available at https://engineerai.space/api/docs

---

# Prediction Flow

1. User interacts with Streamlit App
2. Request passes through Nginx (HTTPS)
3. Gateway authenticates, validates, and proxies the request
4. Inference API performs prediction
5. Model loaded from MLflow alias `prod`
6. Prediction returned to user

---

# Model Lifecycle

Model training, evaluation, promotion, and inference reload are fully automated through the Airflow orchestration layer.

The detailed lifecycle â€” including dataset splitting, MLflow tracking, DVC lineage logging, promotion logic, and registry alias management â€” is documented in:

- `docs/train_pipeline.md`
- `docs/data_pipeline.md`

This separation keeps the README focused on system architecture while maintaining detailed technical traceability in dedicated documentation.

---

# Evaluation Metrics

Primary metric:
- RMSLE (official Solafune metric)

Additional metrics are MAE and RÂ² and all metrics are logged in MLflow.

---

# Monitoring

The platform includes a Prometheus + Grafana observability stack.

Prometheus scrapes:

- **Gateway API** â†’ request volume and latency (`api_requests_total`, `api_request_duration_seconds`)
- **Inference API** â†’ latency (p95), prediction distribution, confidence scores, served model version
- **Infrastructure exporters** â†’ Nginx, host metrics (CPU, memory), Prometheus internal metrics

Alerting rules monitor:

- Service availability (`up`)
- Inference latency (histogram quantiles)
- Request throughput
- Resource usage

Dashboards are accessible via `/grafana` behind Nginx.

---

# Key MLOps Capabilities

- **End-to-end orchestration with Airflow**  
  Automated ingestion â†’ preprocessing â†’ splitting â†’ training â†’ evaluation â†’ promotion â†’ serving reload.

- **Full lineage & reproducible training**  
  DVC versioning (raw, master, splits, reference tests) combined with MLflow tracking and Model Registry (`prod` alias), ensuring deterministic runs and comparable experiments.

- **Strict, versioned configuration system**  
  YAML-based data contracts, feature schemas, model definitions, split strategies, and runtime defaults.

- **Data-driven retraining policy**  
  Automatic retrain trigger based on master dataset growth threshold.

- **Secure microservice architecture**  
  Gateway control plane, isolated inference service, Streamlit frontend, Nginx reverse proxy.

- **Production-grade deployment & observability**  
  Docker & Kubernetes deployment, Prometheus monitoring, Grafana dashboards, Slack notifications, CI automation.

---

# Repository Structure

```
mlops-project/

â”œâ”€â”€ api/                           # FastAPI microservices
â”‚   â”œâ”€â”€ gateway_api/               # API gateway (auth, orchestration)
â”‚   â””â”€â”€ inference_api/             # Model serving microservice
â”‚
â”œâ”€â”€ src/                           # Core ML business library (Python package)
â”‚   â”œâ”€â”€ data/                      # Data ingestion & validation logic
â”‚   â”œâ”€â”€ features/                  # Feature schema & preprocessing pipelines
â”‚   â”œâ”€â”€ models/                    # Model schema & MLflow loader
â”‚   â”œâ”€â”€ inference/                 # Dynamic request schema builder
â”‚   â”œâ”€â”€ registry/                  # MLflow registry utilities
â”‚   â”œâ”€â”€ splitting/                 # Train/test split orchestration
â”‚   â”œâ”€â”€ pipelines/                 # Data & training pipelines (modular)
â”‚   â”œâ”€â”€ training/                  # Metrics & training utilities
â”‚   â””â”€â”€ utils/                     # Config resolution, DVC, logging helpers
â”‚
â”œâ”€â”€ dags/                          # Airflow DAG definitions
â”‚   â”œâ”€â”€ data_pipeline_dag.py
â”‚   â”œâ”€â”€ train_pipeline_dag.py
â”‚   â””â”€â”€ retrain_policy_dag.py
â”‚
â”œâ”€â”€ configs/                       # Versioned YAML configurations
â”‚   â”œâ”€â”€ active_config.yaml
â”‚   â”œâ”€â”€ data_contracts/
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ splits/
â”‚
â”œâ”€â”€ app/                           # Streamlit dashboard (multi-page UI)
â”‚
â”œâ”€â”€ deployments/                   # Docker & Kubernetes manifests
â”‚
â”œâ”€â”€ data/                          # DVC versioned datasets
â”‚   â”œâ”€â”€ incoming/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ splits/
â”‚   â””â”€â”€ reference/
â”‚
â”œâ”€â”€ tests/                         # Unit & integration tests
â”‚
â””â”€â”€ mlflow_server/                 # MLflow backend store & artifacts
```

---

# Running the Platform

Development:

```bash
docker compose -f deployments/compose.yaml -f deployments/compose.dev.yaml up
```

Production:

```bash
docker compose -f deployments/compose.yaml up -d
```

Environment variables managed via `.env`.

---

This project demonstrates a clean, maintainable, production-oriented MLOps architecture, 
designed for internal ML platform usage rather than leaderboard optimization.